# 1.1.1 하둡과 하둡의 생태계에 대한 개요
- `하둡`
    - 방대한 양의 데이터를 처리하는 플랫폼
    - 2005년에 오픈 소스 프로젝트로 소개됨
    - 빅데이터 처리 시스템의 표준
        - 매우 효율적이면서 신뢰할 수 있는 컴퓨터 아키텍처의 기반이 되는 병렬 처리 알고리즘
        - 간단한 데이터 프로세싱 모델
    - 온라인상의 클릭 데이터, 서버 로그, 소셜 미디어, 날씨, 다양한 센서 데이터, 이메일, 휴대폰 데이터 등과 같은 압도적인 양의 데이터를 분석해 데이터의 흐름을 이해하는 빅데이터 분석 니즈를 처리하기 위해 사용
        - 스코틀랜드 독립 옹호론자들이 하둡을 이용해 데이터 분석
        - 커스터머 로열티 프로그램 운영 최적화
        - 소비자 맞춤 제품 추천, 가변적 가격 책정
    - 핵심은 데이터 저장을 담당하는 `HDFS(Hadoop Distributed File System)`와 프로세싱 프레임워크 `YARN(Yet Another Resource Negotiator)`
## 1.1.1.1 하둡의 특징들
- 대용량 데이터 처리 능력
    - 수 페타바이트 또는 엑사바이트 데이터 같은 매우 큰 데이터를 다루기 위해 설계됨
    - 하둡 파일의 사이즈는 수 기가바이트에서 테라바이트에 이르고, 하둡 클러스터를 이용해 이런 파일을 백만 개 이상 저장 가능
- 장애 허용(Fault tolerance)
    - 하드웨어의 장애 발생 가능성을 전제로 설계됨
    - 다수의 서버를 사용해 원하는 일을 동시 처리하면서 서버와 스토리지에 문제가 발생하더라도 장애에 영향을 받지 않고 작업을 이어감
- 높은 장애 대응력(Fault reliant)
    - 기본적으로 데이터를 3벌씩 복사해서 보관하여 YARN이나 HDFS는 1개나 그 이상의 디스크가 작동하지 않아도 작업을 계속 수행
- 데이터의 스트리밍 액세스
    - 수백 개의 웹 페이지에 목차를 달거나 데이터 세트에 스트리밍 액세스하는 것과 같은 배치 프로세싱을 위해 고안됨
- 간단한 데이터 일관성 모델(Simple data consistency model)
    - 한 번 쓰고 많이 읽는 WORM(write-once-read-many access model) 모델을 사용
    - 항상 단 하나의 작업자만 쓸 수 있어서 데이터 일관성 문제가 발생하지 않는다.
## 1.1.1.2 빅데이터와 하둡
- 현대적인 데이터 스토리지와 프로세싱 프레임워크로 다양한 종류의 데이터를 저렴한 비용으로 저장 가능
- 하둡에 저장돼 있는 거대한 양의 데이터를 사용자가 원하는 방식으로 처리 가능
    - 클릭 스트림 데이터, 콜 센터 데이터, 이메일과 인스턴트 메시지, 서버 로그, 세그먼트 데이터, 센서 데이터, 비정형 데이터, 지리 데이터, ...
- 데이터 지역성(data locality)
    - 데이터가 저장되는 곳에서 데이터를 프로세싱
    - HDFS라는 파일 시스템에 데이터를 저장하고 하둡 리소스 관리 시스템인 얀으로 맵리듀스 프로세싱을 클러스터의 노드로 이동
## 1.1.1.3 하둡을 사용하는 일반적 시나리오
- 맵리듀스
    - 키/값 쌍으로 데이터를 정렬하고 합치는 작업
    - 맵
        - 사용자가 마지막으로 방문한 페이지
        - 비워진 장바구니 내용
        - 사용자 트랜잭션 기간
    - 리듀스
        - 맵 단계의 모든 데이터 수집
        - 주간/월간 비워진 장바구니 아이템 수 합산, 사용자가 구입하지 않고 비워진 아이템 전체 값 확인
        - 사용자가 장바구니를 비우고 나가기 전에 방문한 공통 페이지 확인
## 1.1.1.4 전통적인 데이터베이스 시스템
- 온라인 트랜잭션 데이터베이스, 데이터 마트, 데이터 웨어하우스에 구조화된 데이터라고 불리는 비즈니스 데이터를 저장하고 분석
- 비정형 데이터, 일부만 정형화된 데이터(서버 로그, 비디오/오디오 데이터 등) 처리 한계
- 늘어나는 데이터를 감당하기 위해 서버 CPU 코어, RAM, 디스크 스토리지를 추가해야 하는 스케일 업 아키텍처
    - 규모가 커지만 저장 장치에서 CPU로 데이터를 이동할 때 병목 현상 발생    
## 1.1.1.5 데이터 호수
- 데이터의 출처나 데이터를 활용하는 분석 프레임워크에 관계없이 조직의 모든 데이터를 중심부에 저장하여 데이터 처리와 분석 그리드로 사용
    - 정형/비정형 데이터, 일부 정형 데이터 등 종류를 가리지 않고 모든 데이터를 저장
- 데이터 웨어하우스나 다른 저장소로부터 데이터를 가져와서 넘기는 방식으로 데이터 저장 가능
## 1.1.1.6 빅데이터, 데이터 과학 그리고 하둡
- 데이터 제품(data product)
    - 데이터 분석을 통해 얻어진 결과를 이용한 제품
        - 사용자 분석 데이터나 알고리즘
    - 데이터 과학자들이 하둡을 이용해 대규모 데이터를 처리하고 분석하여 데이터 제품을 만듦
        - 아마존의 제품 추천 알고리즘
- 데이터 분석 작업 파이프라인
    - 데이터 수집, 정제, 적재, 분석
    - 데이터 모델링
    - 시각화
    - 보고서
## 1.1.1.7 대용량 데이터 세트와 하둡
- 하둡은 저렴한 비용으로 대용량 데이터 저장, 관계형 데이터 통합(Apache Sqoop), 작업 스케줄링(Apache Oozie) 등의 플랫폼 역할을 한다.
## 1.1.1.1.8 하둡을 적용하기 쉬운 이유
- 6~12개 노드를 사용하는 작은 클러스터를 이용해 POC를 시작할 수 있고 추후 Amazon EC2나 구글 컴퓨트 엔진으로 저렴하게 하둡을 이용할 수 있다.
