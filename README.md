# 하둡 데이터 플랫폼
빅데이터 전문가의 하둡 관리 스터디 노트

## 목차

- **PART I 하둡 소개: 아키텍처와 하둡 클러스터**
  - **Chapter 1 하둡 소개 및 하둡의 주변 환경**
    - [1.1.1 하둡과 하둡의 생태계에 대한 개요](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-1_Overview-of-Hadoop-and-Ecosystem.md)
    - [1.1.2 클러스터 컴퓨팅과 하둡 클러스터들](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-2_Cluster-Computing-and-Hadoop-Clusters.md)
    - [1.1.3 하둡 컴포넌트들과 하둡 생태계](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-3_Hadoop-Components-and-Ecosystem.md)
    - [1.1.4 하둡 관리자들이 하는 일](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-4_What-Hadoop-Administrators-Do.md)
    - [1.1.5 하둡 1과 하둡 2의 주요 차이점](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-5_Key-Differences-between-Hadoop-1-and-Hadoop-2.md)
    - [1.1.6 분산형 데이터 처리: 맵리듀스, 스파크, 하이브, 피그](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-6_Distributed-Data-Processing-MapReduce-Spark-Hive-Pig.md)
    - [1.1.7 데이터 통합: 아파치 스쿱, 아파치 플룸, 아파치 카프카](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-7_Data-Ingestion-Apache-Sqoop-Apache-Flume-Apache-Kafka.md)
    - [1.1.8 하둡 관리의 핵심 영역](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-8_Core-Areas-of-Hadoop-Administration.md)
    - [1.1.9 요약](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-01_Introduction-to-Hadoop-and-Ecosystem/1-1-9_Summary.md)
  - **Chapter 2 하둡 아키텍처 개요**
    - [1.2.1 분산 컴퓨팅과 하둡](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-02_Hadoop-Architecture-Overview/1-2-1_Distributed-Computing-and-Hadoop.md)
    - [1.2.2 하둡 아키텍처](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-02_Hadoop-Architecture-Overview/1-2-2_Hadoop-Architecture.md)
    - [1.2.3 데이터 스토리지 - 하둡 분산 파일 시스템](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-02_Hadoop-Architecture-Overview/1-2-3_Data-Storage-HDFS.md)
    - [1.2.4 하둡 운영 시스템인 얀을 사용한 데이터 프로세싱](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-02_Hadoop-Architecture-Overview/1-2-4_Data-Processing-with-YARN.md)
    - [1.2.5 요약](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-02_Hadoop-Architecture-Overview/1-2-5_Summary.md)
  - **Chapter 3 간단한 하둡 클러스터 생성 및 환경 설정**
    - [1.3.1 하둡 배포판과 설치 타입](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-03_Setting-up-a-Simple-Hadoop-Cluster/1-3-1_Hadoop-Distributions-and-Installation-Types.md)
    - [1.3.2 가상 분산 하둡 클러스터 설정하기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-03_Setting-up-a-Simple-Hadoop-Cluster/1-3-2_Setting-Up-a-Pseudo-Distributed-Hadoop-Cluster.md)
    - [1.3.3 하둡 설정하기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-03_Setting-up-a-Simple-Hadoop-Cluster/1-3-3_Configuring-Hadoop.md)
    - [1.3.4 새로운 하둡 클러스터 운영하기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-03_Setting-up-a-Simple-Hadoop-Cluster/1-3-4_Operating-a-New-Hadoop-Cluster.md)
    - [1.3.5 요약](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-03_Setting-up-a-Simple-Hadoop-Cluster/1-3-5_Summary.md)
  - **Chapter 4 하둡 클러스터 계획하기**
    - [1.4.1 클러스터를 계획할 때 일반적으로 고려해야 할 것들](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-04_Planning-a-Hadoop-Cluster/1-4-1_General-Considerations-for-Cluster-Planning.md)
    - [1.4.2 싱글 랙에서 멀티 랙으로 가기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-04_Planning-a-Hadoop-Cluster/1-4-2_From-Single-Rack-to-Multi-Rack.md)
    - [1.4.3 멀티노드 클러스터 만들기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-04_Planning-a-Hadoop-Cluster/1-4-3_Building-a-Multi-Node-Cluster.md)
    - [1.4.4 하둡 설정 파일 수정하기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-04_Planning-a-Hadoop-Cluster/1-4-4_Updating-Hadoop-Configuration-Files.md)
    - [1.4.5 클러스터 시작하기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-04_Planning-a-Hadoop-Cluster/1-4-5_Starting-the-Cluster.md)
    - [1.4.6 하둡 서비스, 웹 인터페이스 그리고 포트 설정하기](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-04_Planning-a-Hadoop-Cluster/1-4-6_Hadoop-Services-Web-Interfaces-and-Ports.md)
    - [1.4.7 요약](PART-01_Hadoop-Introduction-Architecture-and-Cluster/Chapter-04_Planning-a-Hadoop-Cluster/1-4-7_Summary.md)

- **PART II 하둡 애플리케이션 프레임워크**
  - **Chapter 5 클러스터에서 애플리케이션 실행하기 - 맵리듀스 프레임워크**
    - [2.5.1 맵리듀스 프레임워크](PART-02_Hadoop-Application-Frameworks/Chapter-05_Running-Applications-MapReduce-Framework/2-5-1_MapReduce-Framework.md)
    - [2.5.2 아파치 하이브](PART-02_Hadoop-Application-Frameworks/Chapter-05_Running-Applications-MapReduce-Framework/2-5-2_Apache-Hive.md)
    - [2.5.3 아파치 피그](PART-02_Hadoop-Application-Frameworks/Chapter-05_Running-Applications-MapReduce-Framework/2-5-3_Apache-Pig.md)
    - [2.5.4 요약](PART-02_Hadoop-Application-Frameworks/Chapter-05_Running-Applications-MapReduce-Framework/2-5-4_Summary.md)
  - **Chapter 6 클러스터에서 애플리케이션 실행하기 - 스파크 프레임워크**
    - [2.6.1 스파크는 무엇인가?](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-1_What-is-Spark.md)
    - [2.6.2 왜 스파크인가?](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-2_Why-Spark.md)
    - [2.6.3 스파크 스택](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-3_Spark-Stack.md)
    - [2.6.4 스파크 설치하기](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-4_Installing-Spark.md)
    - [2.6.5 스파크 실행 모드](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-5_Spark-Execution-Modes.md)
    - [2.6.6 클러스터 매니저 이해하기](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-6_Understanding-Cluster-Managers.md)
    - [2.6.7 스파크와 데이터 액세스](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-7_Spark-and-Data-Access.md)
    - [2.6.8 요약](PART-02_Hadoop-Application-Frameworks/Chapter-06_Running-Applications-Spark-Framework/2-6-8_Summary.md)
  - **Chapter 7 스파크 애플리케이션 실행하기**
    - [2.7.1 스파크 프로그래밍 모델](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-1_Spark-Programming-Model.md)
    - [2.7.2 스파크 애플리케이션](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-2_Spark-Applications.md)
    - [2.7.3 스파크 애플리케이션의 아키텍처](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-3_Spark-Application-Architecture.md)
    - [2.7.4 인터랙티브하게 스파크 애플리케이션 실행하기](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-4_Running-Spark-Applications-Interactively.md)
    - [2.7.5 스파크 셸과 스파크 애플리케이션](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-5_Spark-Shell-and-Spark-Applications.md)
    - [2.7.6 스파크 애플리케이션을 만들고 서밋하기](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-6_Building-and-Submitting-Spark-Applications.md)
    - [2.7.7 스파크 애플리케이션 설정하기](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-7_Configuring-Spark-Applications.md)
    - [2.7.8 스파크 애플리케이션 모니터링](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-8_Monitoring-Spark-Applications.md)
    - [2.7.9 스파크 스트리밍으로 스트리밍 데이터 다루기](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-9_Handling-Streaming-Data-with-Spark-Streaming.md)
    - [2.7.10 스파크 SQL을 사용해 구조화된 데이터 처리하기](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-10_Processing-Structured-Data-with-Spark-SQL.md)
    - [2.7.11 요약](PART-02_Hadoop-Application-Frameworks/Chapter-07_Running-Spark-Applications/2-7-11_Summary.md)

- **PART III 하둡 데이터 관리 및 보호 그리고 고가용성**
  - **Chapter 8 네임노드의 역할과 HDFS의 동작 방식**
    - [3.8.1 HDFS - 네임노드와 데이터노드 사이의 상호 연동](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-1_HDFS-NameNode-and-DataNode-Interactions.md)
    - [3.8.2 랙 어웨어니스와 토폴로지](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-2_Rack-Awareness-and-Topology.md)
    - [3.8.3 HDFS의 데이터 복제](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-3_HDFS-Data-Replication.md)
    - [3.8.4 클라이언트가 HDFS 데이터를 읽고 쓰는 방식](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-4_How-Clients-Read-and-Write-HDFS-Data.md)
    - [3.8.5 HDFS 복구 프로세스의 이해](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-5_Understanding-HDFS-Recovery-Processes.md)
    - [3.8.6 HDFS의 중앙집중적 캐시 관리](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-6_Centralized-Cache-Management.md)
    - [3.8.7 하둡의 아카이브 스토리지, SSD와 메모리(이종 스토리지)](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-7_Archive-Storage-SSD-and-Memory-Tiers.md)
    - [3.8.8 요약](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-08_NameNode-Role-and-HDFS-Operation/3-8-8_Summary.md)
  - **Chapter 9 HDFS 명령, 퍼미션, 그리고 스토리지**
    - [3.9.1 HDFS를 HDFS 셸 명령으로 관리하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-09_HDFS-Commands-Permissions-and-Storage/3-9-1_Managing-HDFS-with-Commands.md)
    - [3.9.2 dfsadmin을 이용해 HDFS 오퍼레이션 실행하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-09_HDFS-Commands-Permissions-and-Storage/3-9-2_Using-dfsadmin-for-HDFS-Operations.md)
    - [3.9.3 HDFS 퍼미션과 사용자 관리하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-09_HDFS-Commands-Permissions-and-Storage/3-9-3_HDFS-Permissions-and-User-Management.md)
    - [3.9.4 HDFS 스토리지 관리하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-09_HDFS-Commands-Permissions-and-Storage/3-9-4_Managing-HDFS-Storage.md)
    - [3.9.5 HDFS 데이터 리밸런싱하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-09_HDFS-Commands-Permissions-and-Storage/3-9-5_Rebalancing-HDFS-Data.md)
    - [3.9.6 HDFS 여분의 공간 확보하기(공간 재생)](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-09_HDFS-Commands-Permissions-and-Storage/3-9-6_Reclaiming-Free-Space-in-HDFS.md)
    - [3.9.7 요약](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-09_HDFS-Commands-Permissions-and-Storage/3-9-7_Summary.md)
  - **Chapter 10 데이터 보호, 파일 포맷, 그리고 HDFS 접속**
    - [3.10.1 데이터 보호하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-10_Data-Protection-File-Formats-and-HDFS-Access/3-10-1_Protecting-Data.md)
    - [3.10.2 데이터 압축](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-10_Data-Protection-File-Formats-and-HDFS-Access/3-10-2_Data-Compression.md)
    - [3.10.3 하둡 파일 포맷](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-10_Data-Protection-File-Formats-and-HDFS-Access/3-10-3_Hadoop-File-Formats.md)
    - [3.10.4 하둡의 WebHDFS와 HttpFS 이용하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-10_Data-Protection-File-Formats-and-HDFS-Access/3-10-4_Using-WebHDFS-and-HttpFS.md)
    - [3.10.5 요약](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-10_Data-Protection-File-Formats-and-HDFS-Access/3-10-5_Summary.md)
  - **Chapter 11 네임노드 오퍼레이션, 고가용성 그리고 페더레이션**
    - [3.11.1 네임노드 오퍼레이션 이해하기](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-11_NameNode-Operations-HA-and-Federation/3-11-1_Understanding-NameNode-Operations.md)
    - [3.11.2 체크포인팅 프로세스](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-11_NameNode-Operations-HA-and-Federation/3-11-2_Checkpointing-Process.md)
    - [3.11.3 네임노드의 안전 모드 오퍼레이션](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-11_NameNode-Operations-HA-and-Federation/3-11-3_NameNode-Safe-Mode-Operations.md)
    - [3.11.4 HDFS 고가용성 설정](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-11_NameNode-Operations-HA-and-Federation/3-11-4_Configuring-HDFS-High-Availability.md)
    - [3.11.5 HDFS 연합(HDFS Federation)](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-11_NameNode-Operations-HA-and-Federation/3-11-5_HDFS-Federation.md)
    - [3.11.6 요약](PART-03_Hadoop-Data-Management-Protection-and-High-Availability/Chapter-11_NameNode-Operations-HA-and-Federation/3-11-6_Summary.md)

- **PART IV 데이터 이동, 리소스 할당, 잡 스케줄링 그리고 보안**
  - **Chapter 12 하둡에서 데이터 넣고 빼기**
    - [4.12.1 하둡 데이터 이동을 위한 툴들](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-12_Getting-Data-In-and-Out-of-Hadoop/4-12-1_Tools-for-Hadoop-Data-Movement.md)
    - [4.12.2 명령행을 통해 HDFS에 데이터 로딩하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-12_Getting-Data-In-and-Out-of-Hadoop/4-12-2_Loading-Data-into-HDFS-from-Command-Line.md)
    - [4.12.3 DistCp를 이용해 클러스터 사이에 HDFS 데이터 복사하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-12_Getting-Data-In-and-Out-of-Hadoop/4-12-3_Copying-HDFS-Data-Between-Clusters-with-DistCp.md)
    - [4.12.4 스쿱으로 관계형 데이터베이스 데이터 처리하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-12_Getting-Data-In-and-Out-of-Hadoop/4-12-4_Processing-Relational-Data-with-Sqoop.md)
    - [4.12.5 플룸을 이용해 외부에서 들어오는 데이터 처리하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-12_Getting-Data-In-and-Out-of-Hadoop/4-12-5_Processing-External-Data-with-Flume.md)
    - [4.12.6 카프카를 이용해 데이터 처리하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-12_Getting-Data-In-and-Out-of-Hadoop/4-12-6_Processing-Data-with-Kafka.md)
    - [4.12.7 요약](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-12_Getting-Data-In-and-Out-of-Hadoop/4-12-7_Summary.md)
  - **Chapter 13 하둡 클러스터의 리소스 할당**
    - [4.13.1 하둡에서 리소스 할당](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-13_Resource-Allocation-in-a-Hadoop-Cluster/4-13-1_Resource-Allocation-in-Hadoop.md)
    - [4.13.2 FIFO 스케줄러](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-13_Resource-Allocation-in-a-Hadoop-Cluster/4-13-2_FIFO-Scheduler.md)
    - [4.13.3 Capacity 스케줄러](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-13_Resource-Allocation-in-a-Hadoop-Cluster/4-13-3_Capacity-Scheduler.md)
    - [4.13.4 Fair 스케줄러](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-13_Resource-Allocation-in-a-Hadoop-Cluster/4-13-4_Fair-Scheduler.md)
    - [4.13.5 Capacity 스케줄러와 Fair 스케줄러 비교](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-13_Resource-Allocation-in-a-Hadoop-Cluster/4-13-5_Capacity-vs-Fair-Scheduler.md)
    - [4.13.6 요약](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-13_Resource-Allocation-in-a-Hadoop-Cluster/4-13-6_Summary.md)
  - **Chapter 14 우지(Oozie)로 잡 워크플로 관리하기**
    - [4.14.1 아파치 우지를 이용해 잡 스케줄링하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-1_Scheduling-Jobs-with-Apache-Oozie.md)
    - [4.14.2 우지의 아키텍처](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-2_Oozie-Architecture.md)
    - [4.14.3 클러스터에 우지 설치하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-3_Installing-Oozie-on-a-Cluster.md)
    - [4.14.4 우지 워크플로 이해하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-4_Understanding-Oozie-Workflows.md)
    - [4.14.5 우지가 액션을 실행하는 방법](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-5_How-Oozie-Runs-Actions.md)
    - [4.14.6 우지 워크플로 생성하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-6_Creating-Oozie-Workflows.md)
    - [4.14.7 우지 워크플로 잡 실행하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-7_Running-Oozie-Workflow-Jobs.md)
    - [4.14.8 우지 코디네이터](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-8_Oozie-Coordinator.md)
    - [4.14.9 우지 관리하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-9_Managing-Oozie.md)
    - [4.14.10 요약](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-14_Managing-Job-Workflows-with-Oozie/4-14-10_Summary.md)
  - **Chapter 15 하둡의 보안**
    - [4.15.1 하둡 보안의 개요](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-15_Hadoop-Security/4-15-1_Overview-of-Hadoop-Security.md)
    - [4.15.2 커버로스로 하둡 인증하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-15_Hadoop-Security/4-15-2_Authenticating-with-Kerberos.md)
    - [4.15.3 하둡 인가](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-15_Hadoop-Security/4-15-3_Hadoop-Authorization.md)
    - [4.15.4 하둡 감시하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-15_Hadoop-Security/4-15-4_Auditing-Hadoop.md)
    - [4.15.5 하둡 데이터 안전하게 보관하기](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-15_Hadoop-Security/4-15-5_Securing-Hadoop-Data.md)
    - [4.15.6 기타 하둡의 보안과 관련 프로젝트들](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-15_Hadoop-Security/4-15-6_Other-Security-Related-Projects.md)
    - [4.15.7 요약](PART-04_Data-Movement-Resource-Allocation-Job-Scheduling-and-Security/Chapter-15_Hadoop-Security/4-15-7_Summary.md)

- **PART V 모니터링, 최적화, 그리고 문제 해결**
  - **Chapter 16 잡 관리하기, 휴 사용하기 그리고 반복 작업 수행하기**
    - [5.16.1 YARN 명령을 이용해 하둡 잡 관리하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-1_Managing-Jobs-with-YARN-Commands.md)
    - [5.16.2 노드를 클러스터에서 빼거나 추가하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-2_Removing-or-Adding-Nodes-in-the-Cluster.md)
    - [5.16.3 리소스매니저 고가용 설정(HA 설정)](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-3_ResourceManager-High-Availability-Configuration.md)
    - [5.16.4 일반적인 관리 작업 수행하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-4_Performing-Common-Administration-Tasks.md)
    - [5.16.5 MySQL 데이터베이스 관리하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-5_Managing-MySQL-Databases.md)
    - [5.16.6 중요한 클러스터 데이터 백업하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-6_Backing-Up-Critical-Cluster-Data.md)
    - [5.16.7 휴로 클러스터 관리하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-7_Managing-the-Cluster-with-Hue.md)
    - [5.16.8 특별한 HDFS 기능 사용하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-8_Using-Special-HDFS-Features.md)
    - [5.16.9 요약](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-16_Managing-Jobs-Hue-and-Repetitive-Tasks/5-16-9_Summary.md)
  - **Chapter 17 모니터링, 지표, 그리고 하둡 로깅**
    - [5.17.1 리눅스 서버 모니터링하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-17_Monitoring-Metrics-and-Hadoop-Logging/5-17-1_Monitoring-Linux-Servers.md)
    - [5.17.2 하둡의 평가 지표](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-17_Monitoring-Metrics-and-Hadoop-Logging/5-17-2_Hadoop-Metrics.md)
    - [5.17.3 갱글리아를 이용한 모니터링](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-17_Monitoring-Metrics-and-Hadoop-Logging/5-17-3_Monitoring-with-Ganglia.md)
    - [5.17.4 하둡 로깅 이해하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-17_Monitoring-Metrics-and-Hadoop-Logging/5-17-4_Understanding-Hadoop-Logging.md)
    - [5.17.5 하둡 웹 UI로 모니터링하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-17_Monitoring-Metrics-and-Hadoop-Logging/5-17-5_Monitoring-with-Hadoop-Web-UI.md)
    - [5.17.6 하둡 컴포넌트 모니터링](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-17_Monitoring-Metrics-and-Hadoop-Logging/5-17-6_Monitoring-Hadoop-Components.md)
    - [5.17.7 요약](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-17_Monitoring-Metrics-and-Hadoop-Logging/5-17-7_Summary.md)
  - **Chapter 18 클러스터 리소스 튜닝, 맵리듀스 최적화 그리고 벤치마킹**
    - [5.18.1 얀 메모리와 CPU를 할당하는 방법](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-1_Allocating-YARN-Memory-and-CPU.md)
    - [5.18.2 효율적인 성능을 위한 설정](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-2_Settings-for-Efficient-Performance.md)
    - [5.18.3 맵과 리듀스 태스크 튜닝하기 - 관리자로서 할 수 있는 것](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-3_Tuning-Map-and-Reduce-Tasks.md)
    - [5.18.4 피그와 하이브 잡 최적화하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-4_Optimizing-Pig-and-Hive-Jobs.md)
    - [5.18.5 클러스터 벤치마킹](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-5_Cluster-Benchmarking.md)
    - [5.18.6 하둡 카운터](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-6_Hadoop-Counters.md)
    - [5.18.7 맵리듀스 최적화하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-7_Optimizing-MapReduce-Jobs.md)
    - [5.18.8 요약](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-18_Cluster-Resource-Tuning-MapReduce-Optimization-and-Benchmarking/5-18-8_Summary.md)
  - **Chapter 19 아파치 스파크 설치 및 튜닝**
    - [5.19.1 얀 위에서 동작하는 스파크를 위한 리소스 할당 설정하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-1_Resource-Allocation-for-Spark-on-YARN.md)
    - [5.19.2 리소스가 스파크에 어떻게 할당되는가?](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-2_How-Resources-Are-Allocated-to-Spark.md)
    - [5.19.3 얀에서 스파크 실행 시 동적 리소스 할당하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-3_Dynamic-Resource-Allocation-on-YARN.md)
    - [5.19.4 저장 포맷과 데이터 압축하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-4_Storage-Formats-and-Compression.md)
    - [5.19.5 스파크 애플리케이션 모니터링하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-5_Monitoring-Spark-Applications.md)
    - [5.19.6 가비지 컬렉션 튜닝](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-6_Garbage-Collection-Tuning.md)
    - [5.19.7 스파크 스트리밍 애플리케이션](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-7_Spark-Streaming-Applications.md)
    - [5.19.8 요약](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-19_Apache-Spark-Installation-and-Tuning/5-19-8_Summary.md)
  - **Chapter 20 스파크 애플리케이션 최적화하기**
    - [5.20.1 스파크 실행 모델 다시 보기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-20_Optimizing-Spark-Applications/5-20-1_Revisiting-the-Spark-Execution-Model.md)
    - [5.20.2 셔플 오퍼레이션과 셔플을 최소화하는 방법](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-20_Optimizing-Spark-Applications/5-20-2_Shuffle-Operations-and-Minimizing-Shuffles.md)
    - [5.20.3 파티셔닝과 병렬성(태스크의 수)](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-20_Optimizing-Spark-Applications/5-20-3_Partitioning-and-Parallelism.md)
    - [5.20.4 데이터 직렬화 및 압축의 최적화](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-20_Optimizing-Spark-Applications/5-20-4_Optimizing-Data-Serialization-and-Compression.md)
    - [5.20.5 스파크의 SQL Query 옵티마이저 이해하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-20_Optimizing-Spark-Applications/5-20-5_Understanding-Spark-SQL-Query-Optimizer.md)
    - [5.20.6 데이터 캐시하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-20_Optimizing-Spark-Applications/5-20-6_Caching-Data.md)
    - [5.20.7 요약](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-20_Optimizing-Spark-Applications/5-20-7_Summary.md)
  - **Chapter 21 하둡 문제 해결**
    - [5.21.1 저장 용량 관련 이슈들](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-21_Hadoop-Troubleshooting/5-21-1_Storage-Capacity-Issues.md)
    - [5.21.2 얀의 멈춘 잡 처리하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-21_Hadoop-Troubleshooting/5-21-2_Handling-Stuck-YARN-Jobs.md)
    - [5.21.3 JVM 메모리 할당과 가비지 컬렉션 전략](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-21_Hadoop-Troubleshooting/5-21-3_JVM-Memory-Allocation-and-GC-Strategy.md)
    - [5.21.4 실패 종류에 따른 처리](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-21_Hadoop-Troubleshooting/5-21-4_Handling-Failures-by-Type.md)
    - [5.21.5 스파크 잡 문제 해결하기](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-21_Hadoop-Troubleshooting/5-21-5_Troubleshooting-Spark-Jobs.md)
    - [5.21.6 스파크 애플리케이션 디버깅](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-21_Hadoop-Troubleshooting/5-21-6_Debugging-Spark-Applications.md)
    - [5.21.7 요약](PART-05_Monitoring-Optimization-and-Troubleshooting/Chapter-21_Hadoop-Troubleshooting/5-21-7_Summary.md)

- **부록 A 버추얼박스 및 리눅스 설치 그리고 가상 머신 복사하기**
  - [A.1 오라클 버추얼박스 설치하기](Appendix-A_VirtualBox-and-Linux-Installation-and-VM-Cloning/Install-Oracle-VirtualBox.md)
  - [A.2 오라클 엔터프라이즈 리눅스 설치하기](Appendix-A_VirtualBox-and-Linux-Installation-and-VM-Cloning/Install-Oracle-Enterprise-Linux.md)
  - [A.3 리눅스 서버 복제하기](Appendix-A_VirtualBox-and-Linux-Installation-and-VM-Cloning/Clone-a-Linux-Server.md)

